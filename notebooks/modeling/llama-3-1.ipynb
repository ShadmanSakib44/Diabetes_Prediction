{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10750915,"sourceType":"datasetVersion","datasetId":6667858}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture --no-display\n!curl -fsSL https://ollama.com/install.sh | sh","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:33:25.123817Z","iopub.execute_input":"2025-02-14T19:33:25.124134Z","iopub.status.idle":"2025-02-14T19:34:07.727715Z","shell.execute_reply.started":"2025-02-14T19:33:25.124094Z","shell.execute_reply":"2025-02-14T19:34:07.726788Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import subprocess\nprocess = subprocess.Popen(\"ollama serve\", shell=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:34:26.360118Z","iopub.execute_input":"2025-02-14T19:34:26.360488Z","iopub.status.idle":"2025-02-14T19:34:26.365665Z","shell.execute_reply.started":"2025-02-14T19:34:26.360456Z","shell.execute_reply":"2025-02-14T19:34:26.364556Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"%%capture --no-display\n!ollama pull llama3.1 \n!pip install ollama","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:35:01.045330Z","iopub.execute_input":"2025-02-14T19:35:01.045698Z","iopub.status.idle":"2025-02-14T19:35:41.515112Z","shell.execute_reply.started":"2025-02-14T19:35:01.045663Z","shell.execute_reply":"2025-02-14T19:35:41.513979Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport json\nimport requests","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:37:48.240432Z","iopub.execute_input":"2025-02-14T19:37:48.240964Z","iopub.status.idle":"2025-02-14T19:37:48.245067Z","shell.execute_reply.started":"2025-02-14T19:37:48.240931Z","shell.execute_reply":"2025-02-14T19:37:48.243837Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def get_response_from_server(prompt, model=\"llama3.1\"):\n    url = \"http://127.0.0.1:11434/api/chat\"  # Ollama API endpoint\n    payload = {\n        \"model\": model,\n        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n    }\n    try:\n        response = requests.post(url, json=payload, stream=True)\n        if response.status_code == 200:\n            complete_response = \"\"\n            for line in response.iter_lines():\n                if line:  # Ignore empty lines\n                    try:\n                        chunk = json.loads(line)\n                        if \"message\" in chunk and \"content\" in chunk[\"message\"]:\n                            complete_response += chunk[\"message\"][\"content\"]\n                    except (KeyError, json.JSONDecodeError) as e:\n                        print(\"Warning: Skipped a line due to error -\", str(e))\n            return complete_response.strip()\n        else:\n            return f\"Error: {response.status_code} - {response.text}\"\n    except requests.exceptions.RequestException as e:\n        print(\"Error connecting to the server:\", e)\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:38:02.129494Z","iopub.execute_input":"2025-02-14T19:38:02.129781Z","iopub.status.idle":"2025-02-14T19:38:02.135707Z","shell.execute_reply.started":"2025-02-14T19:38:02.129759Z","shell.execute_reply":"2025-02-14T19:38:02.134968Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Zero Shot Prompt**","metadata":{}},{"cell_type":"code","source":"def predict_diabetes_single_zero_shot(data_row):\n    prompt = f\"\"\"\nYou are a diabetes expert. Evaluate the following patient data and decide if the patient is diabetic.\nAnswer with only a single digit: 1 for diabetic, 0 for non-diabetic. No extra text.\n\nPregnancies: {data_row['Pregnancies']}\nGlucose: {data_row['Glucose']}\nBloodPressure: {data_row['BloodPressure']}\nSkinThickness: {data_row['SkinThickness']}\nInsulin: {data_row['Insulin']}\nBMI: {data_row['BMI']}\nDiabetesPedigreeFunction: {data_row['DiabetesPedigreeFunction']}\nAge: {data_row['Age']}\n\nAnswer:\"\"\"\n    return get_response_from_server(prompt)\n\ndef main():\n    csv_file = '/kaggle/input/diabetes/diabetes_input.csv'\n    df = pd.read_csv(csv_file)\n    \n    predictions = []\n    for _, row in df.iterrows():\n        prediction = predict_diabetes_single_zero_shot(row)\n        predictions.append(prediction)\n    \n    df[\"Predicted_Outcome\"] = predictions\n    output_csv_file = \"/kaggle/working/diabetes_predictions_llama3.1_zero_shot.csv\"\n    df.to_csv(output_csv_file, index=False)\n    \n    print(f\"Predictions saved to {output_csv_file}\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:39:18.093936Z","iopub.execute_input":"2025-02-14T19:39:18.094260Z","iopub.status.idle":"2025-02-14T19:41:10.591115Z","shell.execute_reply.started":"2025-02-14T19:39:18.094235Z","shell.execute_reply":"2025-02-14T19:41:10.590280Z"}},"outputs":[{"name":"stdout","text":"Predictions saved to /kaggle/working/diabetes_predictions_llama3.1_zero_shot.csv\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"**One Shot Prompt**","metadata":{}},{"cell_type":"code","source":"def predict_diabetes_single_one_shot(data_row):\n    prompt = f\"\"\"\nYou are a diabetes expert. Based on the patient data, decide if the patient is diabetic.\nAnswer with a single digit: 1 for diabetic, 0 for non-diabetic. No extra text.\n\nExample:\nPregnancies: 1\nGlucose: 85\nBloodPressure: 66\nSkinThickness: 29\nInsulin: 0\nBMI: 26.6\nDiabetesPedigreeFunction: 0.351\nAge: 31\nAnswer: 0\n\nNow, evaluate this patient:\nPregnancies: {data_row['Pregnancies']}\nGlucose: {data_row['Glucose']}\nBloodPressure: {data_row['BloodPressure']}\nSkinThickness: {data_row['SkinThickness']}\nInsulin: {data_row['Insulin']}\nBMI: {data_row['BMI']}\nDiabetesPedigreeFunction: {data_row['DiabetesPedigreeFunction']}\nAge: {data_row['Age']}\n\nAnswer:\"\"\"\n    return get_response_from_server(prompt)\n\ndef main():\n    csv_file = '/kaggle/input/diabetes/diabetes_input.csv'\n    df = pd.read_csv(csv_file)\n    \n    predictions = []\n    for _, row in df.iterrows():\n        prediction = predict_diabetes_single_one_shot(row)\n        predictions.append(prediction)\n    \n    df[\"Predicted_Outcome\"] = predictions\n    output_csv_file = \"/kaggle/working/diabetes_predictions_llama3.1_one_shot.csv\"\n    df.to_csv(output_csv_file, index=False)\n    \n    print(f\"Predictions saved to {output_csv_file}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:41:42.948641Z","iopub.execute_input":"2025-02-14T19:41:42.949033Z","iopub.status.idle":"2025-02-14T19:43:39.017539Z","shell.execute_reply.started":"2025-02-14T19:41:42.949000Z","shell.execute_reply":"2025-02-14T19:43:39.016731Z"}},"outputs":[{"name":"stdout","text":"Predictions saved to /kaggle/working/diabetes_predictions_llama3.1_one_shot.csv\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"**Three Shot Prompt**","metadata":{}},{"cell_type":"code","source":"def predict_diabetes_single_three_shot(data_row):\n    prompt = f\"\"\"\nYou are a diabetes expert. Use the following examples to decide if a patient is diabetic.\nAnswer with only a single digit: 1 for diabetic, 0 for non-diabetic. No extra text.\n\nExample 1:\nPregnancies: 1\nGlucose: 85\nBloodPressure: 66\nSkinThickness: 29\nInsulin: 0\nBMI: 26.6\nDiabetesPedigreeFunction: 0.351\nAge: 31\nAnswer: 0\n\nExample 2:\nPregnancies: 6\nGlucose: 148\nBloodPressure: 72\nSkinThickness: 35\nInsulin: 0\nBMI: 33.6\nDiabetesPedigreeFunction: 0.627\nAge: 50\nAnswer: 1\n\nExample 3:\nPregnancies: 8\nGlucose: 183\nBloodPressure: 64\nSkinThickness: 0\nInsulin: 0\nBMI: 23.3\nDiabetesPedigreeFunction: 0.672\nAge: 32\nAnswer: 1\n\nNow, evaluate this patient:\nPregnancies: {data_row['Pregnancies']}\nGlucose: {data_row['Glucose']}\nBloodPressure: {data_row['BloodPressure']}\nSkinThickness: {data_row['SkinThickness']}\nInsulin: {data_row['Insulin']}\nBMI: {data_row['BMI']}\nDiabetesPedigreeFunction: {data_row['DiabetesPedigreeFunction']}\nAge: {data_row['Age']}\n\nAnswer:\"\"\"\n    return get_response_from_server(prompt)\n\ndef main():\n    csv_file = '/kaggle/input/diabetes/diabetes_input.csv'\n    df = pd.read_csv(csv_file)\n    \n    predictions = []\n    for _, row in df.iterrows():\n        prediction = predict_diabetes_single_three_shot(row)\n        predictions.append(prediction)\n    \n    df[\"Predicted_Outcome\"] = predictions\n    output_csv_file = \"/kaggle/working/diabetes_predictions_mistral_three_shot.csv\"\n    df.to_csv(output_csv_file, index=False)\n    \n    print(f\"Predictions saved to {output_csv_file}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:45:48.973934Z","iopub.execute_input":"2025-02-14T19:45:48.974262Z","iopub.status.idle":"2025-02-14T19:47:48.033541Z","shell.execute_reply.started":"2025-02-14T19:45:48.974238Z","shell.execute_reply":"2025-02-14T19:47:48.032419Z"}},"outputs":[{"name":"stdout","text":"Predictions saved to /kaggle/working/diabetes_predictions_mistral_three_shot.csv\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}